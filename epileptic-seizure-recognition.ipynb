{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EPILEPTIC SEIZURE RECOGNITION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Manipulation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw = pd.read_csv(\"epileptic-seizure-recognition.csv\")\n",
    "raw = raw.drop(\"Unnamed\",axis=1)\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = raw[\"y\"]\n",
    "e = []\n",
    "for x in range(0,len(raw)):\n",
    "    if y[x] in [2,3,4,5]: \n",
    "        e.append(0)\n",
    "    else:\n",
    "        e.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw.append(e)\n",
    "\n",
    "raw.insert(179,\"e\",e,True)\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Principal Component Analysis for Data Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features = raw.columns[0:178]\n",
    "X = raw.loc[:, features].values\n",
    "y = raw.loc[:,\"y\"]\n",
    "e = raw.loc[:,\"e\"]\n",
    "\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, e_train, e_test = train_test_split(X, e, test_size = 0.25, random_state = 21, stratify = e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA \n",
    "import pandas as pd\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.io import output_notebook,reset_output,save,show\n",
    "\n",
    "output_notebook()\n",
    "def pca_visualization(X,y):\n",
    "    pca = PCA(n_components = 2)\n",
    "    pc = pca.fit_transform(X)\n",
    "    pcDF = pd.DataFrame(data = pc, columns = ['pc1','pc2'])\n",
    "    pcDF['e'] = y.values\n",
    "    epilepsy = pcDF.loc[pcDF['e']==1,]\n",
    "    not_epilepsy = pcDF.loc[pcDF['e']==0,]\n",
    "    reset_output()\n",
    "    output_notebook()\n",
    "    p = figure()\n",
    "    p.scatter(x = epilepsy['pc1'], \n",
    "              y = epilepsy['pc2'], \n",
    "              marker=\"x\", \n",
    "              fill_alpha=0.5, \n",
    "              size=6, \n",
    "              legend = \"Epilepsy\")\n",
    "    p.scatter(x = not_epilepsy['pc1'], \n",
    "              y = not_epilepsy['pc2'], \n",
    "              marker=\"triangle\", \n",
    "              fill_alpha=0.3, \n",
    "              size=6, \n",
    "              fill_color=\"orange\",\n",
    "              line_color=\"orange\",\n",
    "              legend = \"Not Epilepsy\")\n",
    "    p.xaxis.axis_label = \"Principal Component 1\"\n",
    "    p.yaxis.axis_label = \"Principal Component 2\"\n",
    "    show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_visualization(X_train,e_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rate = np.mean(e_train)\n",
    "length = len(e_train)\n",
    "\n",
    "print(\"There are {}\".format(length), \"examples in the training set and only {}\".format(round(length*rate)), \"of them are labeled as Epilepsy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Over-Sampling with SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "oversampling = SMOTE()\n",
    "X_train_b, e_train_b = oversampling.fit_resample(X_train,e_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter_imb = Counter(e_train)\n",
    "counter_b = Counter(e_train_b)\n",
    "\n",
    "print(counter_imb)\n",
    "print(counter_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_visualization(X_train_b,e_train_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = np.mean(e_train_b)\n",
    "length = len(e_train_b)\n",
    "\n",
    "print(\"There are {}\".format(length), \"examples in the training set after SMOTE and now {}\".format(round(length*rate)), \"of them are labeled as Epilepsy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Principal Component Analysis for Speeding Up the Machine Learning Algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 40)\n",
    "pca.fit(X_train_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reduced_pca = pca.transform(X_train_b)\n",
    "X_test_reduced_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Importance with Extra Tree Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "feature_imp = []\n",
    "\n",
    "for x in range(1,500):\n",
    "    model = ExtraTreesClassifier()\n",
    "    model.fit(X_train_b,e_train_b)\n",
    "    feature_imp =+ model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from heapq import nlargest, nsmallest\n",
    "\n",
    "largest40 = nlargest(40, enumerate(feature_imp), itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest40_col_name = []\n",
    "largest40_values = []\n",
    "largest40_index = []\n",
    "\n",
    "for index, value in largest40: \n",
    "    name = 's'+ str(index+1)\n",
    "    largest40_col_name.append(name)\n",
    "    largest40_values.append(value)\n",
    "    largest40_index.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "\n",
    "p = figure(y_range = largest40_col_name, title = \"Most Important 40 Features\", x_axis_label = \"Importance\", tools = \"\")\n",
    "p.hbar(y = largest40_col_name, right = largest40_values, left = 0, height = 0.5, color = 'orange', fill_alpha = 0.5)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_f_reduced = X_train_b[:,largest40_index]\n",
    "X_test_f_reduced = X_test[:,largest40_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sequential Forward Feature Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "\n",
    "mdl = KNeighborsClassifier(n_neighbors = 1)\n",
    "\n",
    "sequential_forward = sfs(mdl,\n",
    "                         k_features=40,\n",
    "                         forward=True,\n",
    "                         floating=False,\n",
    "                         verbose=2,\n",
    "                         scoring='accuracy',\n",
    "                         cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_forward_forward = step_forward.fit(X_train_b, e_train_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = list(sequential_forward.k_feature_idx_)\n",
    "print(feat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "\n",
    "fig = plot_sfs(sequential_forward.get_metric_dict(), kind='std_dev')\n",
    "\n",
    "plt.ylim([0.75, 1])\n",
    "plt.title('Sequential Forward Selection')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sf_reduced = X_train_b[:,feat_cols]\n",
    "X_test_sf_reduced = X_test[:,feat_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-Nearest Neighbors after Feature Extraction with Principal Component Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def model_comparison(X_train, y_train, X_test, y_test, model, parameters, cv, scoring):\n",
    "    model_cv = GridSearchCV(model, parameters, cv = cv, scoring = scoring)\n",
    "    model_cv.fit(X_train,y_train)\n",
    "    prediction = model_cv.predict(X_test)\n",
    "    prediction_prob = model_cv.predict_proba(X_test)[:,1]\n",
    "    print(\"Classification report:\\n\\n\",classification_report(prediction,y_test))\n",
    "    plot_confusion_matrix(model_cv, X_test, y_test,\n",
    "                          display_labels = ['Not Epilepsy','Epilepsy'],\n",
    "                          cmap = plt.cm.Blues, \n",
    "                          values_format = \".2f\")\n",
    "    return prediction, prediction_prob, model_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "param_knn = {'n_neighbors':np.arange(1,5)}\n",
    "\n",
    "knn_prediction_pca, knn_prediction_prob_pca, knn_pca = model_comparison(X_train = X_train_reduced_pca,\n",
    "                                                                        y_train = e_train_b, \n",
    "                                                                        X_test = X_test_reduced_pca,\n",
    "                                                                        y_test = e_test, \n",
    "                                                                        model = KNeighborsClassifier(),\n",
    "                                                                        parameters = param_knn,\n",
    "                                                                        cv=10, scoring= 'f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-Nearest Neighbors after Feature Selection with Extra Trees Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_prediction_f, knn_prediction_prob_f, knn_f = model_comparison(X_train = X_train_f_reduced,\n",
    "                                                                  y_train = e_train_b, \n",
    "                                                                  X_test = X_test_f_reduced,\n",
    "                                                                  y_test = e_test, \n",
    "                                                                  model = KNeighborsClassifier(),\n",
    "                                                                  parameters = param_knn,\n",
    "                                                                  cv=10, scoring= 'f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-Nearest Neighbors after Feature Selection with Sequential Forward Feature Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "param_knn = {'n_neighbors':np.arange(1,5)}\n",
    "knn_prediction_sf, knn_prediction_prob_sf, knn_sf = model_comparison(X_train = X_train_sf_reduced,\n",
    "                                                                     y_train = e_train_b, \n",
    "                                                                     X_test = X_test_sf_reduced,\n",
    "                                                                     y_test = e_test, \n",
    "                                                                     model = KNeighborsClassifier(),\n",
    "                                                                     parameters = param_knn,\n",
    "                                                                     cv=10, scoring= 'f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "param_dtc = {'max_depth':         [200,250,300,1000],\n",
    "             'max_features':      [25,30,35],\n",
    "             'min_samples_split': [5,10,20,30,40,50],\n",
    "             'min_samples_leaf':  [25,50,150,250,500,1000]}\n",
    "\n",
    "dtc_prediction_pca, dtc_prediction_prob_pca, dtc_pca = model_comparison(X_train = X_train_reduced_pca,\n",
    "                                                                        y_train = e_train_b, \n",
    "                                                                        X_test  = X_test_reduced_pca,\n",
    "                                                                        y_test  = e_test, \n",
    "                                                                        model   = DecisionTreeClassifier(),\n",
    "                                                                        parameters = param_dtc,\n",
    "                                                                        cv = 10, \n",
    "                                                                        scoring = 'f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_rf = {'n_estimators': [300,500,700],\n",
    "            'max_features': [3,5,7],\n",
    "            'max_depth':    [80,100,120]}\n",
    "\n",
    "rf_prediction_pca, rf_prediction_prob_pca, rf_pca = model_comparison(X_train = X_train_reduced_pca,\n",
    "                                                                     y_train = e_train_b, \n",
    "                                                                     X_test = X_test_reduced_pca,\n",
    "                                                                     y_test = e_test, \n",
    "                                                                     model = RandomForestClassifier(),\n",
    "                                                                     parameters = param_rf,\n",
    "                                                                     cv=10, scoring = 'precision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.layers import Activation\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "X_reduced_pca = np.concatenate((X_train_reduced_pca,X_test_reduced_pca))\n",
    "e_reduced_pca = np.concatenate((e_train_b, e_test))\n",
    "\n",
    "kf_cv = KFold(10, shuffle=True, random_state = 42)\n",
    "\n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "def tuning_parameters(learning_rate, epochs):\n",
    "    for train, test in kf_cv.split(X_reduced_pca):       \n",
    "        x_train = X_reduced_pca[train]\n",
    "        y_train = e_reduced_pca[train]\n",
    "        x_test = X_reduced_pca[test]\n",
    "        y_test = e_reduced_pca[test]\n",
    "    \n",
    "        nn = Sequential()\n",
    "        nn.add(Dense(100, input_dim = 40, activation = 'relu'))\n",
    "        nn.add(Dense(100, activation = 'relu'))\n",
    "        nn.add(Dense(1, activation = 'sigmoid'))\n",
    "        opt = Adam(lr = learning_rate)\n",
    "        nn.compile(loss='binary_crossentropy', optimizer=opt, metrics=tf.keras.metrics.RecallAtPrecision(precision=0.9))\n",
    "    \n",
    "        nn.fit(x_train,y_train,validation_data=(x_test,y_test), epochs = epochs, verbose = 0)\n",
    "    \n",
    "        y_pred = nn.predict_classes(x_test)\n",
    "    \n",
    "        oos_y.append(y_test)\n",
    "        oos_y_concat = np.concatenate(oos_y)\n",
    "    \n",
    "        oos_pred.append(y_pred)    \n",
    "        oos_pred_concat = np.concatenate(oos_pred)\n",
    "    \n",
    "    f1_score = metrics.f1_score(oos_pred_concat,oos_y_concat)\n",
    "    rec = metrics.recall_score(oos_pred_concat,oos_y_concat)\n",
    "    prec = metrics.precision_score(oos_pred_concat,oos_y_concat)\n",
    "    return f1_score, rec, prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.0001,0.001, 0.01, 0.1, 1]\n",
    "\n",
    "f1 = []\n",
    "rec = []\n",
    "prec = []\n",
    "\n",
    "for i in range(len(learning_rates)): \n",
    "    x,y,z = tuning_parameters(learning_rate = learning_rates[i], epochs = 100)\n",
    "    f1.append(x)\n",
    "    rec.append(y)\n",
    "    prec.append(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_pca = Sequential()\n",
    "nn_pca.add(Dense(1200, input_dim = 40, activation = 'relu'))\n",
    "nn_pca.add(Dense(1200, activation = 'relu'))\n",
    "nn_pca.add(Dense(1200, activation = 'relu'))\n",
    "nn_pca.add(Dense(1, activation = 'sigmoid'))\n",
    "opt = Adam(lr = 0.001)\n",
    "nn_pca.compile(loss='binary_crossentropy', optimizer=opt, metrics=tf.keras.metrics.Recall())\n",
    "nn_pca.fit(X_train_reduced_pca,e_train_b,validation_data=(X_test_reduced_pca,e_test), epochs = 30, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix as plot_cm\n",
    "\n",
    "nn_prediction_prob_pca = nn_pca.predict(X_test_reduced_pca)\n",
    "nn_prediction_prob_pca_cm = (nn_prediction_prob_pca > 0.5)\n",
    "\n",
    "nn_prediction_pca = nn_pca.predict_classes(X_test_reduced_pca)\n",
    "\n",
    "cm = confusion_matrix(e_test, nn_prediction_prob_pca_cm)\n",
    "\n",
    "class_names = ['Not Epilepsy', 'Epilepsy']\n",
    "\n",
    "fig,ax  = plot_cm(conf_mat=cm,\n",
    "                  colorbar=True,\n",
    "                  class_names = class_names,\n",
    "                  figsize = (6,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, plot_precision_recall_curve, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "precision_knn, recall_knn, _ = precision_recall_curve(e_test,knn_prediction_prob_pca)\n",
    "precision_dtc, recall_dtc, _ = precision_recall_curve(e_test,dtc_prediction_prob_pca)\n",
    "precision_rf, recall_rf, _ = precision_recall_curve(e_test,rf_prediction_prob_pca)\n",
    "precision_nn, recall_nn, _ = precision_recall_curve(e_test,nn_prediction_prob_pca)\n",
    "\n",
    "f1_knn = f1_score(e_test, knn_prediction_pca)\n",
    "f1_dtc = f1_score(e_test, dtc_prediction_pca)\n",
    "f1_rf = f1_score(e_test, rf_prediction_pca)\n",
    "f1_nn = f1_score(e_test, nn_prediction_pca)\n",
    "\n",
    "fig = plt.figure(figsize= (10,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.plot(recall_knn, precision_knn, label = \"K-Nearest Neighbors (F1 = {:.5f})\".format(f1_knn), c = 'gray')\n",
    "ax.plot(recall_dtc, precision_dtc, label = \"Decision Tree (F1 = {:.5f})\".format(f1_dtc), c = 'orange')\n",
    "ax.plot(recall_rf, precision_rf, label = \"Random Forest (F1 = {:.5f})\".format(f1_rf), c = 'purple')\n",
    "ax.plot(recall_nn, precision_nn, label = \"Neural Network (F1 = {:.5f})\".format(f1_nn), c = 'green')\n",
    "\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Recall\")\n",
    "ax.set_ylabel(\"Precision\")\n",
    "ax.set_title(\"Precision Recall Curve for Different Models\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, precision_score\n",
    "def specificity_score(e_act, e_pred, threshold): \n",
    "    return sum((e_pred < threshold) & (e_act == 0))/sum(e_act == 0)\n",
    "\n",
    "def report(e_act, e_pred, threshold): \n",
    "    precision = precision_score(e_act, (e_pred>threshold))\n",
    "    recall = recall_score(e_test, (e_pred>threshold))\n",
    "    specificity = specificity_score(e_act, e_pred, threshold)\n",
    "    accuracy = accuracy_score(e_act, (e_pred>threshold))\n",
    "    print('Precision:%.5f'%precision)   \n",
    "    print('Recall:%.5f'%recall)\n",
    "    print('Specificity:%.5f'%specificity)\n",
    "    print('Accuracy:%.5f'%accuracy)\n",
    "    return precision, recall, specificity, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"The performance of the models on the test set are summarised in the table below:\\n\")    \n",
    "print(\"\\033[1m\" + \"K-Nearest Neighbors\"+ '\\033[0m')\n",
    "precision_knn, recall_knn, specificity_knn, accuracy_knn = report(e_test, knn_prediction_prob_pca, threshold = 0.5)   \n",
    "print(\"\\n\")\n",
    "print(\"\\033[1m\" + \"Decision Tree\"+ '\\033[0m')\n",
    "precision_dtc, recall_dtc, specificity_dtc, accuracy_dtc = report(e_test, dtc_prediction_prob_pca, threshold = 0.5)   \n",
    "print(\"\\n\")\n",
    "print(\"\\033[1m\" + \"Random Forest\"+ '\\033[0m')\n",
    "precision_rf, recall_rf, specificity_rf, accuracy_rf = report(e_test, rf_prediction_prob_pca, threshold = 0.5)   \n",
    "print(\"\\n\")\n",
    "print(\"\\033[1m\" + \"Neural Network\"+ '\\033[0m')\n",
    "precision_nn, recall_nn, specificity_nn, accuracy_nn = report(e_test, nn_prediction_prob_pca.flatten(), threshold = 0.5)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = tuple([precision_knn,precision_dtc,precision_rf,precision_nn,\n",
    "                     recall_knn,recall_dtc,recall_rf,recall_nn,\n",
    "                     specificity_knn ,specificity_dtc ,specificity_rf,specificity_nn,\n",
    "                     accuracy_knn , accuracy_dtc , accuracy_rf, accuracy_nn])\n",
    "\n",
    "metrics = np.concatenate([[\"Precision\"],\n",
    "                          [\"Recall\"],\n",
    "                          [\"Specificity\"],\n",
    "                          [\"Accuracy\"]])\n",
    "\n",
    "models = [\"K-Nearest Neighbors\", \"Decision Tree\",\"Random Forest\", \"Neural Network\"]\n",
    "\n",
    "stacked = [(metric,model) for metric in metrics for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from bokeh.models import ColumnDataSource, FactorRange\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.palettes import Viridis3\n",
    "from bokeh.models import LabelSet\n",
    "from bokeh.transform import factor_cmap\n",
    "\n",
    "reset_output()\n",
    "output_notebook()\n",
    "\n",
    "x = stacked\n",
    "y = np.round(np.array(performance)*100,2)\n",
    "\n",
    "source = ColumnDataSource(data=dict(x=x, y=y))\n",
    "\n",
    "p = figure(x_range=FactorRange(*x), \n",
    "           plot_height=400, \n",
    "           plot_width = 1200, \n",
    "           title=\"Model Comparison from Different Perspectives\",\n",
    "           toolbar_location=None, \n",
    "           tools=\"\")\n",
    "\n",
    "p.vbar(x='x', \n",
    "       top='y', \n",
    "       width=0.9, \n",
    "       source=source,\n",
    "       fill_color = factor_cmap('x', \n",
    "                                 palette = Viridis3, \n",
    "                                 factors = models, \n",
    "                                 start = 1, \n",
    "                                 end = 3))\n",
    "\n",
    "labels = LabelSet(x='x', \n",
    "                  y='y', \n",
    "                  text='y', \n",
    "                  level='glyph',\n",
    "                  x_offset=-13, \n",
    "                  y_offset=0, \n",
    "                  source=source, \n",
    "                  text_font_size=\"11px\",\n",
    "                  render_mode='canvas')\n",
    "\n",
    "p.add_layout(labels)\n",
    "p.title.text_font_size = \"12px\"\n",
    "p.y_range.start = 0\n",
    "p.x_range.range_padding = 0.1\n",
    "p.yaxis.axis_label = 'Performance(%)'\n",
    "p.xaxis.major_label_orientation = 1\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis of Incorrect Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_ind = rf_pca.predict(X_test_reduced_pca)!=e_test\n",
    "correct_ind = rf_pca.predict(X_test_reduced_pca)==e_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_df = pd.DataFrame(X_test[incorrect_ind])\n",
    "incorrect_df[\"e\"] = e_test.values[incorrect_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_df = pd.DataFrame(X_test[correct_ind])\n",
    "correct_df[\"e\"] = e_test.values[correct_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = incorrect_df[incorrect_df[\"e\"]==0]\n",
    "fn = incorrect_df[incorrect_df[\"e\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn = correct_df[correct_df[\"e\"]==0]\n",
    "tp = correct_df[correct_df[\"e\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tn.T.boxplot(figsize = (30,300),vert=False)\n",
    "plt.xlim(-7.75,13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp.T.boxplot(figsize = (30,13),vert=False)\n",
    "plt.xlim(-7.75,13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tn.boxplot(figsize = (30,30),vert=False)\n",
    "plt.xlim(-7.85,13.90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fp.boxplot(figsize = (30,30),vert=False)\n",
    "plt.xlim(-7.85,13.90)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
